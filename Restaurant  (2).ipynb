{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the important Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt   \n",
    "import matplotlib.style\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_excel(\"Restro Data_Train.xlsx\")\n",
    "df_test=pd.read_excel(\"Restro Data_Test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>RESTAURANT_ID</th>\n",
       "      <th>CUISINES</th>\n",
       "      <th>TIME</th>\n",
       "      <th>CITY</th>\n",
       "      <th>LOCALITY</th>\n",
       "      <th>RATING</th>\n",
       "      <th>VOTES</th>\n",
       "      <th>COST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CASUAL DINING</td>\n",
       "      <td>9438</td>\n",
       "      <td>Malwani, Goan, North Indian</td>\n",
       "      <td>11am – 4pm, 7:30pm – 11:30pm (Mon-Sun)</td>\n",
       "      <td>Thane</td>\n",
       "      <td>Dombivali East</td>\n",
       "      <td>3.6</td>\n",
       "      <td>49 votes</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CASUAL DINING,BAR</td>\n",
       "      <td>13198</td>\n",
       "      <td>Asian, Modern Indian, Japanese</td>\n",
       "      <td>6pm – 11pm (Mon-Sun)</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Ramapuram</td>\n",
       "      <td>4.2</td>\n",
       "      <td>30 votes</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CASUAL DINING</td>\n",
       "      <td>10915</td>\n",
       "      <td>North Indian, Chinese, Biryani, Hyderabadi</td>\n",
       "      <td>11am – 3:30pm, 7pm – 11pm (Mon-Sun)</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Saligramam</td>\n",
       "      <td>3.8</td>\n",
       "      <td>221 votes</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QUICK BITES</td>\n",
       "      <td>6346</td>\n",
       "      <td>Tibetan, Chinese</td>\n",
       "      <td>11:30am – 1am (Mon-Sun)</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Bandra West</td>\n",
       "      <td>4.1</td>\n",
       "      <td>24 votes</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DESSERT PARLOR</td>\n",
       "      <td>15387</td>\n",
       "      <td>Desserts</td>\n",
       "      <td>11am – 1am (Mon-Sun)</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Lower Parel</td>\n",
       "      <td>3.8</td>\n",
       "      <td>165 votes</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TITLE  RESTAURANT_ID  \\\n",
       "0      CASUAL DINING           9438   \n",
       "1  CASUAL DINING,BAR          13198   \n",
       "2      CASUAL DINING          10915   \n",
       "3        QUICK BITES           6346   \n",
       "4     DESSERT PARLOR          15387   \n",
       "\n",
       "                                     CUISINES  \\\n",
       "0                 Malwani, Goan, North Indian   \n",
       "1              Asian, Modern Indian, Japanese   \n",
       "2  North Indian, Chinese, Biryani, Hyderabadi   \n",
       "3                            Tibetan, Chinese   \n",
       "4                                    Desserts   \n",
       "\n",
       "                                     TIME     CITY        LOCALITY RATING  \\\n",
       "0  11am – 4pm, 7:30pm – 11:30pm (Mon-Sun)    Thane  Dombivali East    3.6   \n",
       "1                    6pm – 11pm (Mon-Sun)  Chennai       Ramapuram    4.2   \n",
       "2     11am – 3:30pm, 7pm – 11pm (Mon-Sun)  Chennai      Saligramam    3.8   \n",
       "3                 11:30am – 1am (Mon-Sun)   Mumbai     Bandra West    4.1   \n",
       "4                    11am – 1am (Mon-Sun)   Mumbai     Lower Parel    3.8   \n",
       "\n",
       "       VOTES  COST  \n",
       "0   49 votes  1200  \n",
       "1   30 votes  1500  \n",
       "2  221 votes   800  \n",
       "3   24 votes   800  \n",
       "4  165 votes   300  "
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12690, 9), (4231, 8))"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape of dataset\n",
    "\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12690 entries, 0 to 12689\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   TITLE          12690 non-null  object\n",
      " 1   RESTAURANT_ID  12690 non-null  int64 \n",
      " 2   CUISINES       12690 non-null  object\n",
      " 3   TIME           12690 non-null  object\n",
      " 4   CITY           12578 non-null  object\n",
      " 5   LOCALITY       12592 non-null  object\n",
      " 6   RATING         12688 non-null  object\n",
      " 7   VOTES          11486 non-null  object\n",
      " 8   COST           12690 non-null  int64 \n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 892.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Type</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>int64</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>object</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Column Type  Count\n",
       "0       int64      2\n",
       "1      object      7"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check train column types\n",
    "\n",
    "col = df_train.dtypes.reset_index()\n",
    "col.columns = [\"Count\", \"Column Type\"]\n",
    "col.groupby(\"Column Type\").aggregate('count').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TITLE               0\n",
       "RESTAURANT_ID       0\n",
       "CUISINES            0\n",
       "TIME                0\n",
       "CITY              112\n",
       "LOCALITY           98\n",
       "RATING              2\n",
       "VOTES            1204\n",
       "COST                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for NULL values\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TITLE            0.00\n",
       "RESTAURANT_ID    0.00\n",
       "CUISINES         0.00\n",
       "TIME             0.00\n",
       "CITY             0.88\n",
       "LOCALITY         0.77\n",
       "RATING           0.02\n",
       "VOTES            9.49\n",
       "COST             0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's check the percentage of NULL Values\n",
    "round(df_train.isnull().sum()/len(df_train)*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dummy dataframe\n",
    "dummy = [df_train[['TITLE', 'RESTAURANT_ID', 'CUISINES', 'TIME', 'CITY', 'LOCALITY','RATING', 'VOTES']], df_test]\n",
    "\n",
    "dummy = pd.concat(dummy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Max Titles in a Cell :  2\n",
      "\n",
      "\n",
      "Number of Unique Titles :  25\n",
      "\n",
      "\n",
      "Unique Titles:\n",
      " ['CASUAL DINING' 'BAR' 'QUICK BITES' 'DESSERT PARLOR' 'CAFÉ'\n",
      " 'MICROBREWERY' 'BEVERAGE SHOP' 'IRANI CAFE' 'BAKERY' 'NONE' 'PUB'\n",
      " 'FINE DINING' 'SWEET SHOP' 'LOUNGE' 'FOOD COURT' 'FOOD TRUCK' 'MESS'\n",
      " 'KIOSK' 'CLUB' 'CONFECTIONERY' 'DHABA' 'MEAT SHOP' 'COCKTAIL BAR'\n",
      " 'PAAN SHOP' 'BHOJANALYA']\n"
     ]
    }
   ],
   "source": [
    "#Title column has no missing values\n",
    "#let's analyse how many unique titles we have with us\n",
    "\n",
    "\n",
    "titles = list(dummy['TITLE']) #Storing all the titles in a list\n",
    "\n",
    "# Finding Max number of titles mentioned in a single cell\n",
    "mx = 1\n",
    "for i in titles :\n",
    "    if len(i.split(',')) > mx:\n",
    "         mx = len(i.split(','))\n",
    "         \n",
    "print(\"\\n\\nMax Titles in a Cell : \", mx)    \n",
    "\n",
    "all_titles = []\n",
    "\n",
    "for i in titles :\n",
    "    if len(i.split(',')) == 1:\n",
    "         all_titles.append(i.split(',')[0].strip().upper())\n",
    "    else :\n",
    "        for it in range(len(i.split(','))):\n",
    "            all_titles.append(i.split(',')[it].strip().upper())\n",
    "\n",
    "print(\"\\n\\nNumber of Unique Titles : \", len(pd.Series(all_titles).unique()))\n",
    "print(\"\\n\\nUnique Titles:\\n\", pd.Series(all_titles).unique())\n",
    "\n",
    "all_titles = list(pd.Series(all_titles).unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = list(df_train['TITLE'])\n",
    "\n",
    "# Since Maximum number of titles in a cell is 2 will will split title in to 2 columns\n",
    "T1 = []\n",
    "T2 = []\n",
    "\n",
    "for i in titles:\n",
    "    T1.append(i.split(',')[0].strip().upper())\n",
    "    try :\n",
    "         T2.append(i.split(',')[1].strip().upper())\n",
    "    except :\n",
    "         T2.append('NONE')\n",
    "\n",
    "# appending NONE to Unique titles list\n",
    "all_titles.append('NONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Max cuisines in a Cell :  8\n",
      "\n",
      "\n",
      "Number of Unique Cuisines :  130\n",
      "\n",
      "\n",
      "Unique Cuisines:\n",
      " ['MALWANI' 'GOAN' 'NORTH INDIAN' 'ASIAN' 'MODERN INDIAN' 'JAPANESE'\n",
      " 'CHINESE' 'BIRYANI' 'HYDERABADI' 'TIBETAN' 'DESSERTS' 'SEAFOOD' 'CAFE'\n",
      " 'PIZZA' 'BURGER' 'BAR FOOD' 'SOUTH INDIAN' 'FAST FOOD' 'BEVERAGES'\n",
      " 'ARABIAN' 'MUGHLAI' 'MAHARASHTRIAN' 'PARSI' 'THAI' 'BAKERY' 'MOMOS'\n",
      " 'CONTINENTAL' 'EUROPEAN' 'ROLLS' 'ANDHRA' 'ITALIAN' 'BBQ' 'FINGER FOOD'\n",
      " 'TEA' 'AMERICAN' 'HEALTHY FOOD' 'COFFEE' 'INDONESIAN' 'KOREAN' 'NEPALESE'\n",
      " 'ICE CREAM' 'MEXICAN' 'KERALA' 'INDIAN' 'MITHAI' 'STREET FOOD'\n",
      " 'MALAYSIAN' 'VIETNAMESE' 'IRANIAN' 'KEBAB' 'JUICES' 'SANDWICH'\n",
      " 'MEDITERRANEAN' 'SALAD' 'GUJARATI' 'RAJASTHANI' 'TEX-MEX' 'ROAST CHICKEN'\n",
      " 'BURMESE' 'CHETTINAD' 'NORTH EASTERN' 'LEBANESE' 'COFFEE AND TEA' 'GRILL'\n",
      " '' 'BIHARI' 'BENGALI' 'LUCKNOWI' 'AWADHI' 'STEAK' 'FRENCH' 'PORTUGUESE'\n",
      " 'WRAPS' 'SRI LANKAN' 'ORIYA' 'ETHIOPIAN' 'KONKAN' 'SUSHI' 'SPANISH'\n",
      " 'RUSSIAN' 'MANGALOREAN' 'TURKISH' 'BUBBLE TEA' 'AFGHAN' 'NAGA'\n",
      " 'SINGAPOREAN' 'GERMAN' 'MIDDLE EASTERN' 'SINDHI' 'CANTONESE' 'HOT POT'\n",
      " 'PAN ASIAN' 'SATAY' 'DUMPLINGS' 'KASHMIRI' 'RAW MEATS' 'DRINKS ONLY'\n",
      " 'MOROCCAN' 'PANINI' 'CAFE FOOD' 'CHARCOAL CHICKEN' 'BELGIAN' 'MONGOLIAN'\n",
      " 'TAMIL' 'AFRICAN' 'PAAN' 'ASSAMESE' 'HOT DOGS' 'POKÉ' 'BRITISH' 'BOHRI'\n",
      " 'FUSION' 'ARMENIAN' 'SOUTH AMERICAN' 'GREEK' 'PAKISTANI' 'PERUVIAN'\n",
      " 'CUISINE VARIES' 'IRISH' 'MULTI CUISINE' 'JEWISH' 'VEGAN' 'ORIENTAL'\n",
      " 'MODERN AUSTRALIAN' 'EGYPTIAN' 'FISH AND CHIPS' 'BRAZILIAN' 'MISHTI'\n",
      " 'FALAFEL' 'HAWAIIAN']\n"
     ]
    }
   ],
   "source": [
    "#We do not have any missing values in cuisines either\n",
    "cuisines = list(dummy['CUISINES'])\n",
    "\n",
    "mx = 1\n",
    "for i in cuisines :\n",
    "    if len(i.split(',')) > mx:\n",
    "         mx = len(i.split(','))\n",
    "         \n",
    "print(\"\\n\\nMax cuisines in a Cell : \", mx)    \n",
    "\n",
    "all_cuisines = []\n",
    "\n",
    "for i in cuisines :\n",
    "    if len(i.split(',')) == 1:\n",
    "         #print(i.split(',')[0])\n",
    "         all_cuisines.append(i.split(',')[0].strip().upper())\n",
    "    else :\n",
    "        for it in range(len(i.split(','))):\n",
    "            #print(i.split(',')[it])\n",
    "            all_cuisines.append(i.split(',')[it].strip().upper())\n",
    "\n",
    "print(\"\\n\\nNumber of Unique Cuisines : \", len(pd.Series(all_cuisines).unique()))\n",
    "print(\"\\n\\nUnique Cuisines:\\n\", pd.Series(all_cuisines).unique())\n",
    "\n",
    "all_cuisines = list(pd.Series(all_cuisines).unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisines = list(df_train['CUISINES'])\n",
    "   \n",
    "# Since Maximum number of cuisines in a cell is 8 will will split title in to 8 columns\n",
    "   \n",
    "C1 = []\n",
    "C2 = []\n",
    "C3 = []\n",
    "C4 = []\n",
    "C5 = []\n",
    "C6 = []\n",
    "C7 = []\n",
    "C8 = []\n",
    "\n",
    "\n",
    "for i in cuisines:\n",
    "        try :\n",
    "            C1.append(i.split(',')[0].strip().upper())\n",
    "        except :\n",
    "            C1.append('NONE')\n",
    "        try :\n",
    "            C2.append(i.split(',')[1].strip().upper())\n",
    "        except :\n",
    "            C2.append('NONE')\n",
    "        try :\n",
    "            C3.append(i.split(',')[2].strip().upper())\n",
    "        except :\n",
    "            C3.append('NONE')\n",
    "        try :\n",
    "            C4.append(i.split(',')[3].strip().upper())\n",
    "        except :\n",
    "            C4.append('NONE')\n",
    "        try :\n",
    "            C5.append(i.split(',')[4].strip().upper())\n",
    "        except :\n",
    "            C5.append('NONE')\n",
    "        try :\n",
    "            C6.append(i.split(',')[5].strip().upper())\n",
    "        except :\n",
    "            C6.append('NONE')\n",
    "        try :\n",
    "            C7.append(i.split(',')[6].strip().upper())\n",
    "        except :\n",
    "            C7.append('NONE')\n",
    "        try :\n",
    "            C8.append(i.split(',')[7].strip().upper())\n",
    "        except :\n",
    "            C8.append('NONE')\n",
    "\n",
    "# appending NONE to Unique cuisines list\n",
    "all_cuisines.append('NONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Number of Unique cities (Including NOT AVAILABLE):  445\n",
      "\n",
      "\n",
      "Unique Cities:\n",
      " ['THANE' 'CHENNAI' 'MUMBAI' 'BANGALORE' 'GURGAON' 'HYDERABAD' 'KOCHI'\n",
      " 'THANE WEST' 'ANDHERI LOKHANDWALA' 'NEW DELHI' 'ANDHERI WEST'\n",
      " 'MALAD EAST' '682036' 'BANGALOR' 'NAVI MUMBAI' 'BANDRA WEST' 'DELHI'\n",
      " 'NOIDA' 'BANGALORE-560066' 'SECUNDERABAD' 'NOT AVAILABLE' 'INDIA'\n",
      " 'MADHURANAGAR' 'CHENNAI TEYNAMPET' 'FARIDABAD' 'CHEMBUR.' 'MAHARASHTRA'\n",
      " 'OPP GURUDWARA SHAKURPUR' 'TELAGANA LAND LINE:040-48507016' 'GHAZIABAD'\n",
      " 'KARNATAKA' 'KERALA' 'EDAPPALLY' 'KADAVANTHRA' 'ERNAKULAM CIRCLE KOCHI'\n",
      " 'BENGALORE' 'NEAR RELIANCE FRESH' 'KILPAUK' 'BENGALURU' 'KOTHAGUDA'\n",
      " 'GOREGAON WEST' 'BANGLORE' 'TAMIL NADU' 'KAKKANAD' 'KOCHI ELAMKULAM'\n",
      " 'OUTER RING ROAD' 'MULUND EAST'\n",
      " 'SECUNDERABAD MAIN ROAD NEAR SIGNAL NMREC COLLEGE' 'TELANGANA'\n",
      " 'PONNURUNI KOCHI' 'GACHIBOWLI' 'SEMMANCHERI'\n",
      " '5TH MAIN TEACHERS COLONY KORAMANGALA BLOCK 1 BANGALORE 560034'\n",
      " 'MUMBAI MAHIM' 'POWAI (NEXT TO POWAI PLAZA)' 'DOMBIVALI EAST'\n",
      " 'KOCHI VYTTILA' 'KANDIVALI' 'KOCHI PALARIVATTOM' 'DEWAN RAMA ROAD'\n",
      " 'GURUGRAM' 'SECTOR 51 NOIDA' 'KALOOR' 'BESANT NAGAR'\n",
      " 'ARUMBAKKAM CHENNAI-600106.' 'ADJACENT TO COMMERCIAL STREET' 'DELHI NCR'\n",
      " 'DWARKA' '682035.' 'KALYAN WEST' 'AVADI' 'KONDAPUR' 'MEHDIPATNAM'\n",
      " 'GANDIPET' 'VELACHERY' 'PALLAVARAM' 'VIJAYA NAGAR' 'BTM LAYOUT'\n",
      " 'CHENNAI 600034.'\n",
      " 'METRO PILLAR NO 21. METTUGUDA MAIN ROAD NEAR RAILWAY DEGREE COLLEGE.'\n",
      " 'CHENNAI - 600040' 'JP NAGAR BANGALORE' 'MADHAPUR' 'ERNAKULAM' 'SARJAPUR'\n",
      " 'WHITEFIELD BANGALORE' 'KOCHI CHULLICKAL' 'KOCHI-683101'\n",
      " 'BANGALORE - 560076' 'ROHINI' 'HYDERABAD BEHIND VACS PASTRIES'\n",
      " 'HYDERABAD NEERUS EMPORIUM.' 'NAVI MUMBAI.' 'KAROL BAGH' 'PERUNGUDI'\n",
      " 'THYKOODAM' 'GREATER NOIDA' 'BANGALORE.' 'KHAIRATABAD' 'CHULLICKAL'\n",
      " 'GRANT ROAD WEST' 'HITECH CITY' 'WEST MAREDPALLY' 'MUMBAI - 400007'\n",
      " 'CHENNAI PADUR' 'CHANDER NAGAR NEW DELHI' 'NEDUMBASSERY' 'MG ROAD'\n",
      " 'NAYA NAGAR MIRA ROAD' 'PITAMPURA' 'LOWER PAREL' 'HBR LAYOUT'\n",
      " 'TELANGANA 500003' 'RAJIV GANDHI NAGAR' 'NEW DELHI.' 'MEDAVAKKAM'\n",
      " 'SATHYA NAGAR' 'P.O KOCHI' 'BEHIND RAMALAYAM TEMPLE' 'PALARIVATTOM'\n",
      " 'BRIGADE ROAD' 'MUMBAI.' 'MUMBAI ANDHERI EAST' 'VIRAR WEST' 'B-1 STAGE'\n",
      " 'CHENNAI KOVALAM' 'HYDERABAD.' 'ALUVA' 'TELANGANA 500034'\n",
      " 'IOB BANK KAMALA NAGAR' 'HSR LAYOUT' 'MARINE DRIVE' 'DLF GALLERIA'\n",
      " 'NALLATHAMBI MAIN ROAD' 'CHENNAI OPP: VASANTH & CO' 'CITYPARK'\n",
      " 'KARNATAKA 560103' 'BHAYANDAR' 'ALUVA CIRCLE' 'THAMMENAHALLI VILLAGE'\n",
      " 'SG PALYA' 'ATTAPUR.' 'NEAR SHANGRILLA BUS STOP' 'KHAR (WEST)' 'ROAD 3'\n",
      " 'KUKATPALLY' 'FARIDABD' 'TELANGANA 500032' 'DILSUKHNAGAR'\n",
      " 'MOGAPPAIR. CHENNAI' 'NEAR MUNRSHWARA TEMPLE' 'OFF BRIGADE ROAD'\n",
      " 'KHAR WEST' 'POTHERI' 'CHENNAI PERUNGUDI' 'CHENNAI THURAIPAKKAM'\n",
      " 'OMR KARAPAKKAM' 'HYDERABAD-500032' 'MUMBAI DOMBIVALI EAST'\n",
      " 'CHENNAI THOUSAND LIGHTS' 'MAHIM' 'LINGAMPALLY' 'POWAI'\n",
      " 'NEW DELHI-110024' 'CHENNAI- 600107' 'KERALA 683104' 'VASAI WEST.'\n",
      " 'THANE (W)' 'NEAR SANTOSH BANJARA HYDERABAD'\n",
      " 'BANASWADI (NEXT TO INDIAN BANK) BANGALORE' 'BTM BANGALORE'\n",
      " 'GREATER KAILASH 2 NEW DELHI' 'SECUNDERABAD ECIL'\n",
      " 'BANGALORE KORAMANGALA 7TH BLOCK' 'BANGALORE : 560085'\n",
      " 'GACHIBOWLI HYDERABAD'\n",
      " 'CPR LAYOUT HARLUR MAIN ROAD OPPOSITE TO OZONE EVER GREEN APARTMENT BANGALORE -'\n",
      " 'ECR NEELANKARAI CHENNAI 600115' 'WARD X11' 'PERUMBAVOOR'\n",
      " 'MIRA RAOD EAST' 'KERALA 682013' 'CHENNAI.' 'POKHRAN ROAD 2'\n",
      " 'UTTAR PRADESH' 'KARNATAKA 560102' 'MUMBAI - 400013' 'NAHARPAR'\n",
      " 'HOSUR ROAD' 'NEAR BHARAT PETROLEUM.'\n",
      " 'CHENNAI (BANG OPPOSITE INDIAN BANK)' 'SRIRAM NAGAR' 'WEST MUMBAI'\n",
      " 'VYTTILA' 'BANJARA HILLS' 'MALAPALLIPURAM P .O THRISSUR'\n",
      " 'ANDHERI WEST MUMBAI' 'KARNATAKA 560043' 'PANAMPILLY NAGAR'\n",
      " 'BORIVALI EAST.' 'ECIL' 'JUBILEE HILLS'\n",
      " 'AMRIT KAUR MARKET OPPOSITE NEW DELHI RAILWAY STATION PAHARGANJ'\n",
      " 'CHENNAI OPPOSITE 5C BUS STAND' 'TELENGANA' 'KOCHI RAVIPURAM' 'RAJANPADA'\n",
      " 'MAHABALIPURAM' 'SECUNDERABAD. WE HAVE NO BRANCHES.' 'TELANGANA 500081'\n",
      " 'GURGOAN' 'ELAMAKKARA' 'SECTOR 1' 'BANDRA W' 'KOLATHUR'\n",
      " 'CHENNAI MAHABALIPURAM' '3RD STREET' 'MUMBAI CHAKALA' 'BORIVALI WEST'\n",
      " 'RODEO DRIVE SECTOR 49' 'PALLIMUKKU' 'DELHI 110085' 'SECTOR 51'\n",
      " 'CHAMPAPET' 'ANDAVAR NAGAR' 'BANGALORE - 560103' 'KERALA 690525'\n",
      " 'OPP MUKTESHWAR ASHRAM POWAI' 'NUNGAMBAKKAM' 'BK GUDA'\n",
      " 'JOGESHWARI (W) MUMBAI' 'KUKATAPALLY' 'NEAR SECTOR 110 NOIDA' 'NAVALLUR'\n",
      " 'BESIDE EXCELLENCY GARDENS' 'MUMBAI - 80' 'BEGUMPET'\n",
      " 'MAHARAJA HOTEL BESIDE GARDANIA BAR' 'ASHOK VIHAR PHASE 1' 'TRIVANDRUM'\n",
      " 'KOCHI-18' 'NARAYANGUDA' 'THEVERA' 'CHENNAI-40' 'PALM BEACH ROAD'\n",
      " 'EAST COAST ROAD (ECR)' 'RAMAPURAM' 'CHENNAI CHROMPET' 'NANDANAM' 'SAKET'\n",
      " 'MG ROAD ERNAKULAM' 'ANDHERI LOKHANDWALA.' 'INDIRANAGAR' 'THIRUVANMIYUR'\n",
      " 'AMBATTUR' 'BANGLAORE' 'CHENNAI - 34 LANDMARK - NEAR LOYOLA COLLEGE'\n",
      " 'ANNA NAGAR WEST' 'OLD RAILWAY ROAD' 'EAST MUMBAI'\n",
      " 'KANAKAPURA ROAD BANGLORE' 'KOCHI KAKKANAD' 'KALYAN'\n",
      " 'NEAR RAMLILA GROUND' 'SERILINGAMPALLY' 'HIMAYATH NAGAR' 'NALLALA STREET'\n",
      " 'ANNA SALAI' 'OLD DELHI' 'WAGLE ESTATE' '1ST STAGE' 'KOCHI-16'\n",
      " 'KOCHI INTERNATIONAL AIRPORT VIP ROAD' 'FIRST STREET' 'CHENN AI'\n",
      " '6 & 7 - 4/64 SUBHASH NAGAR' '1ST TAVAREKERE' 'PERAMBUR'\n",
      " 'VAISHALI GHAZIABAD' 'THANISANDRA' 'BLOCK F' 'SECTOR 7 DWARKA'\n",
      " 'OPPOSITE BARATHI GAS COMPANY' 'VADAPALANI' 'KONDAPUR.' 'BADLAPUR WEST.'\n",
      " 'KALAMASSERY' 'PALAVAKKAM' 'TCS SYNERGY PARK' 'BTM 1ST STAGE'\n",
      " 'MAHADEVPURA' 'NEW BEL ROAD 560054'\n",
      " 'VELIAVEETIL HOUSE VIVEKANANDA NAGAR ELAMAKKARA' 'SHOLINGANALLUR'\n",
      " 'MAHARASHTRA 400102' 'LOWER PAREL WEST' 'TRIPUNITHURA' 'MOGAPPAIR'\n",
      " 'TELANGANA 500070' 'JP NAGAR' 'NAVI-MUMBAI' 'ASHOK NAGAR' 'MARATHAHALLI'\n",
      " 'HARIDWAR APARTMENTS' 'KERALA 682001 INDIA' 'KARNATAKA 560037'\n",
      " 'KERALA 683585' 'CHENNAI. (NEAR HOTEL MATSHYA)' 'INDIRAPURAM'\n",
      " 'BEGUMPET HYDERABAD' 'MANIKONDA'\n",
      " 'BANGALORE LAND MARK ABOVE MAHAVEER HARD WARE' 'KERALA 682304'\n",
      " 'RAJARAJESHWARI NAGAR BANGALORE' 'GST ROAD' 'FORT KOCHI'\n",
      " 'LAHARI APARTMENTS' 'RAMANTHAPUR' 'MULUND WEST' 'GURGAON HARYANA INDIA'\n",
      " 'NEW DELHI..NEAR BY SBI BANK' 'KOCHI ALUVA 102' 'PHASE 1 BANGALORE'\n",
      " 'HYDERABAD MANIKONDA'\n",
      " 'MUMBAI THIS IS A DELIVERY & TAKE-AWAY RESTAURANT ONLY.' '10TH AVENUE'\n",
      " 'UPPAL' 'NEW DELHI 110075' 'NIZAMPET' 'ULSOO' 'BANGALORE 560076'\n",
      " 'PVR PLAZA CINEMA BUILDING CONNAUGHT PLACE' 'GURGAON HARYANA' 'CHROMEPET'\n",
      " 'KERALA 682024' 'JANAKPURI' 'SECUNDERABAD.'\n",
      " 'B.B.M.P EAST (KARNATAKA) - 560049' 'TAMBARAM' 'MALLESHWARAM BANGALORE'\n",
      " 'VADAPALANI.' 'DIST. CENTER NEW DELHI' 'BANGALORE ROAD' 'KOCHI.'\n",
      " 'THANE MUMBAI' 'KADUBESANAHALLI BANGALORE' 'VASAI WEST'\n",
      " 'MIG HOUSING SOCIETY' 'HARYANA' 'BORIVALI WEST.' 'GOLF COURSE ROAD'\n",
      " 'KHAR MUMBAI' 'NEAR JYOTHINIVAS COLLEGE' 'ANNA NAGAR EAST' 'MASAB TANK'\n",
      " 'VASAI MUMBAI' 'PANATHUR MAIN ROAD' 'NEAR ANDHERI WEST STATION'\n",
      " 'OPPOSITE TO WESTERN SIDE OF ITPL SERVICE GATE' 'KALKAJI' 'APR CHAMBERS'\n",
      " 'TAMIL NADU 600102' 'MAHARASHTRA.' 'GANDHINAGAR RD'\n",
      " 'NEAR ANDHERI EAST STATION' 'WHITEFIELD' 'KERALA 682036'\n",
      " 'MIRA ROAD THANE MUMBAI' 'INDIA GATE NEW DELHI' 'BANGALORE - 560095'\n",
      " 'SHOLINGANALLUR. CHENNAI' 'CHENNAI (ABOVE BOMBAY BRASSERIE)' 'CHENNAI 37'\n",
      " '682024' 'GIRGAUM' 'GREATER KAILASH 1 (GK 1) NEW DELHI' 'KURLA (W)'\n",
      " 'MUMBAI 400015' 'THANE WEST THANE WEST' 'KOCHI PANAMPILLY NAGAR' 'MARAD'\n",
      " 'MAHARASHTRA 400092' 'NEAR SECTOR 34' 'MEHDIPATNAM HYDERABAD'\n",
      " 'NALLAGANDLA' 'VANDALUR' 'CHENNAI 40' 'SECUNDERBAD' 'MM NAGAR'\n",
      " 'MUMBAI 400070' 'CHITTETHUKKARA' 'BTM' 'DOMBIVLI' 'SAHAKARA NAGAR'\n",
      " 'MOHAMMAD ALI ROAD MUMBAI' 'CHENNAI 600040' 'TAVAREKERE MAIN ROAD'\n",
      " 'COMMUNITY CENTRE' 'KERALA 682022' 'DELH.' 'SECTOR-6 NOIDA 201301'\n",
      " 'KAARAIKUDI COMPLEX' 'THIRUVANMIYUR (OPP EUROKIDS LB ROAD)'\n",
      " 'VIRAR MUMBAI' 'TOLICHOWKI' 'HYDERABA' 'KERALA 682305' 'ALWARPET'\n",
      " 'KERALA 682015' 'MUMBAI VEERA DESAI AREA' 'KERALA 682018' 'KERALA 682028'\n",
      " 'SURARAM' 'CHENNAI VELACHERY'\n",
      " 'FORUM SUJANA MALL OPPOSITE TO MALAYSIAN TOWNSHIP' 'OLD HAFEEZPET'\n",
      " 'YOUSUFGUDA' 'CHENNAI-600008' 'MUMBAI ULHASNAGAR'\n",
      " 'JOGESHWARI WEST MUMBAI' 'CHEPAUK' 'CHOWPATTY' 'CHURCH STREET'\n",
      " 'BALAVINAYAGAR NAGAR CHENNAI' 'T-NAGAR CHENNAI' 'RA PURAM'\n",
      " 'HYDERABAD.STAR HYPERMARKET OPPOSITE SIDE SERVICE ROAD'\n",
      " 'CHENNAI INJAMBAKKAM' 'MUMBAI MUMBRA' 'HABSIGUDA' 'KURLA MUMBAI'\n",
      " 'TELANGANA 500027' 'CHENNA' 'KERALA 682021' 'KANDIVALI WEST'\n",
      " 'CHENNAI-119' 'NOIDA EXTENTION' 'SHIHAB THANGAL ROAD' 'NEW DELHI 110011'\n",
      " 'MIUMBAI' 'BORIVALI (W) MUMBAI: 400 092.' 'VANASTHALIPURAM' 'KK ROAD'\n",
      " 'CHENNAI - 600018' 'OPPOSITE ELLORA BUILDING']\n"
     ]
    }
   ],
   "source": [
    "#Now, we have noticed that a few cities have pin codes in them. let us detect those values and fill them with NA\n",
    "all_cities = list(dummy['CITY'])\n",
    "\n",
    "for i in range(len(all_cities)):\n",
    "    if type(all_cities[i]) == float:\n",
    "        all_cities[i] = 'NOT AVAILABLE'\n",
    "    all_cities[i] = all_cities[i].strip().upper()\n",
    "        \n",
    "print(\"\\n\\nNumber of Unique cities (Including NOT AVAILABLE): \", len(pd.Series(all_cities).unique()))\n",
    "print(\"\\n\\nUnique Cities:\\n\", pd.Series(all_cities).unique())\n",
    " \n",
    "all_cities = list(pd.Series(all_cities).unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, we will replace the NAN values in CITY with NA\n",
    "cities = list(df_train['CITY'])\n",
    "\n",
    "for i in range(len(cities)):\n",
    "    if type(cities[i]) == float:\n",
    "        cities[i] = 'NOT AVAILABLE'\n",
    "    cities[i] = cities[i].strip().upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Number of Unique Localities (Including NOT AVAILABLE) :  1611\n",
      "\n",
      "\n",
      "Unique Localities:\n",
      " ['DOMBIVALI EAST' 'RAMAPURAM' 'SALIGRAMAM' ... 'OFF CARTER ROAD'\n",
      " 'SRM BACK GATE' 'PERRY CROSS ROAD']\n"
     ]
    }
   ],
   "source": [
    "#Let's extract the number of unique localities and the list of unique localities\n",
    "all_localities = list(dummy['LOCALITY'])\n",
    "\n",
    "for i in range(len(all_localities)):\n",
    "    if type(all_localities[i]) == float:\n",
    "        all_localities[i] = 'NOT AVAILABLE'\n",
    "    all_localities[i] = all_localities[i].strip().upper()\n",
    "        \n",
    "print(\"\\n\\nNumber of Unique Localities (Including NOT AVAILABLE) : \", len(pd.Series(all_localities).unique()))\n",
    "print(\"\\n\\nUnique Localities:\\n\", pd.Series(all_localities).unique())\n",
    "\n",
    "all_localities = list(pd.Series(all_localities).unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will replace the NAN values in LOCALITY with NA\n",
    "localities = list(df_train['LOCALITY'])\n",
    "\n",
    "for i in range(len(localities)):\n",
    "    if type(localities[i]) == float:\n",
    "        localities[i] = 'NOT AVAILABLE'\n",
    "    localities[i] = localities[i].strip().upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, in Ratings column, we have a lot of missing values. other than the missing values, we have values like NEW for new restaurants and '-' for those whose ratings are not available**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's now convert rating into float type and remove the missing values as well\n",
    "rating = list(df_train['RATING'])\n",
    "\n",
    "for i in range(len(rating)) :\n",
    "    try:\n",
    "       rating[i] = float(rating[i])\n",
    "    except :\n",
    "       rating[i] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In the votes column, we have a mixture of integers and characters. Charaters are useless, so we remove them\n",
    "votes = list(df_train['VOTES'])\n",
    "\n",
    "for i in range(len(votes)) :\n",
    "    try:\n",
    "       votes[i] = int(votes[i].split(\" \")[0].strip())\n",
    "    except :\n",
    "       pass "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, we have stored all the features in the form of lists. We need to store those lists in a new dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = {}\n",
    "\n",
    "train_df['TITLE1'] = T1\n",
    "train_df['TITLE2'] = T2\n",
    "train_df['RESTAURANT_ID'] = df_train[\"RESTAURANT_ID\"]\n",
    "train_df['CUISINE1'] = C1\n",
    "train_df['CUISINE2'] = C2\n",
    "train_df['CUISINE3'] = C3\n",
    "train_df['CUISINE4'] = C4\n",
    "train_df['CUISINE5'] = C5\n",
    "train_df['CUISINE6'] = C6\n",
    "train_df['CUISINE7'] = C7\n",
    "train_df['CUISINE8'] = C8\n",
    "train_df['CITY'] = cities\n",
    "train_df['LOCALITY'] = localities\n",
    "train_df['RATING'] = rating\n",
    "train_df['VOTES'] = votes\n",
    "train_df['COST'] = df_train[\"COST\"]\n",
    "\n",
    "train_df = pd.DataFrame(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE1</th>\n",
       "      <th>TITLE2</th>\n",
       "      <th>RESTAURANT_ID</th>\n",
       "      <th>CUISINE1</th>\n",
       "      <th>CUISINE2</th>\n",
       "      <th>CUISINE3</th>\n",
       "      <th>CUISINE4</th>\n",
       "      <th>CUISINE5</th>\n",
       "      <th>CUISINE6</th>\n",
       "      <th>CUISINE7</th>\n",
       "      <th>CUISINE8</th>\n",
       "      <th>CITY</th>\n",
       "      <th>LOCALITY</th>\n",
       "      <th>RATING</th>\n",
       "      <th>VOTES</th>\n",
       "      <th>COST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CASUAL DINING</td>\n",
       "      <td>NONE</td>\n",
       "      <td>9438</td>\n",
       "      <td>MALWANI</td>\n",
       "      <td>GOAN</td>\n",
       "      <td>NORTH INDIAN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>THANE</td>\n",
       "      <td>DOMBIVALI EAST</td>\n",
       "      <td>3.6</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CASUAL DINING</td>\n",
       "      <td>BAR</td>\n",
       "      <td>13198</td>\n",
       "      <td>ASIAN</td>\n",
       "      <td>MODERN INDIAN</td>\n",
       "      <td>JAPANESE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>CHENNAI</td>\n",
       "      <td>RAMAPURAM</td>\n",
       "      <td>4.2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CASUAL DINING</td>\n",
       "      <td>NONE</td>\n",
       "      <td>10915</td>\n",
       "      <td>NORTH INDIAN</td>\n",
       "      <td>CHINESE</td>\n",
       "      <td>BIRYANI</td>\n",
       "      <td>HYDERABADI</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>CHENNAI</td>\n",
       "      <td>SALIGRAMAM</td>\n",
       "      <td>3.8</td>\n",
       "      <td>221.0</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QUICK BITES</td>\n",
       "      <td>NONE</td>\n",
       "      <td>6346</td>\n",
       "      <td>TIBETAN</td>\n",
       "      <td>CHINESE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>BANDRA WEST</td>\n",
       "      <td>4.1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DESSERT PARLOR</td>\n",
       "      <td>NONE</td>\n",
       "      <td>15387</td>\n",
       "      <td>DESSERTS</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>LOWER PAREL</td>\n",
       "      <td>3.8</td>\n",
       "      <td>165.0</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           TITLE1 TITLE2  RESTAURANT_ID      CUISINE1       CUISINE2  \\\n",
       "0   CASUAL DINING   NONE           9438       MALWANI           GOAN   \n",
       "1   CASUAL DINING    BAR          13198         ASIAN  MODERN INDIAN   \n",
       "2   CASUAL DINING   NONE          10915  NORTH INDIAN        CHINESE   \n",
       "3     QUICK BITES   NONE           6346       TIBETAN        CHINESE   \n",
       "4  DESSERT PARLOR   NONE          15387      DESSERTS           NONE   \n",
       "\n",
       "       CUISINE3    CUISINE4 CUISINE5 CUISINE6 CUISINE7 CUISINE8     CITY  \\\n",
       "0  NORTH INDIAN        NONE     NONE     NONE     NONE     NONE    THANE   \n",
       "1      JAPANESE        NONE     NONE     NONE     NONE     NONE  CHENNAI   \n",
       "2       BIRYANI  HYDERABADI     NONE     NONE     NONE     NONE  CHENNAI   \n",
       "3          NONE        NONE     NONE     NONE     NONE     NONE   MUMBAI   \n",
       "4          NONE        NONE     NONE     NONE     NONE     NONE   MUMBAI   \n",
       "\n",
       "         LOCALITY  RATING  VOTES  COST  \n",
       "0  DOMBIVALI EAST     3.6   49.0  1200  \n",
       "1       RAMAPURAM     4.2   30.0  1500  \n",
       "2      SALIGRAMAM     3.8  221.0   800  \n",
       "3     BANDRA WEST     4.1   24.0   800  \n",
       "4     LOWER PAREL     3.8  165.0   300  "
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, we need to do the same with test set as well**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copying all the codes for training set to test set\n",
    "\n",
    "\n",
    "# TITLE\n",
    "titles = list(df_test['TITLE'])\n",
    "\n",
    "# Since Maximum number of titles in a cell is 2 will will split title in to 2 columns\n",
    "T1 = []\n",
    "T2 = []\n",
    "\n",
    "for i in titles:\n",
    "    T1.append(i.split(',')[0].strip().upper())\n",
    "    try :\n",
    "         T2.append(i.split(',')[1].strip().upper())\n",
    "    except :\n",
    "         T2.append('NONE')\n",
    "\n",
    "\n",
    "#Cleaning CUISINES \n",
    "\n",
    "cuisines = list(df_test['CUISINES'])\n",
    "   \n",
    "# Since Maximum number of cuisines in a cell is 8 will will split title in to 8 columns\n",
    "   \n",
    "C1 = []\n",
    "C2 = []\n",
    "C3 = []\n",
    "C4 = []\n",
    "C5 = []\n",
    "C6 = []\n",
    "C7 = []\n",
    "C8 = []\n",
    "\n",
    "\n",
    "for i in cuisines:\n",
    "        try :\n",
    "            C1.append(i.split(',')[0].strip().upper())\n",
    "        except :\n",
    "            C1.append('NONE')\n",
    "        try :\n",
    "            C2.append(i.split(',')[1].strip().upper())\n",
    "        except :\n",
    "            C2.append('NONE')\n",
    "        try :\n",
    "            C3.append(i.split(',')[2].strip().upper())\n",
    "        except :\n",
    "            C3.append('NONE')\n",
    "        try :\n",
    "            C4.append(i.split(',')[3].strip().upper())\n",
    "        except :\n",
    "            C4.append('NONE')\n",
    "        try :\n",
    "            C5.append(i.split(',')[4].strip().upper())\n",
    "        except :\n",
    "            C5.append('NONE')\n",
    "        try :\n",
    "            C6.append(i.split(',')[5].strip().upper())\n",
    "        except :\n",
    "            C6.append('NONE')\n",
    "        try :\n",
    "            C7.append(i.split(',')[6].strip().upper())\n",
    "        except :\n",
    "            C7.append('NONE')\n",
    "        try :\n",
    "            C8.append(i.split(',')[7].strip().upper())\n",
    "        except :\n",
    "            C8.append('NONE')\n",
    "\n",
    "\n",
    "# Cleaning CITY\n",
    "\n",
    "cities = list(df_test['CITY'])\n",
    "\n",
    "for i in range(len(cities)):\n",
    "    if type(cities[i]) == float:\n",
    "        cities[i] = 'NOT AVAILABLE'\n",
    "    cities[i] = cities[i].strip().upper()\n",
    "        \n",
    "\n",
    "# Cleaning LOCALITY\n",
    "\n",
    "localities = list(df_test['LOCALITY'])\n",
    "\n",
    "for i in range(len(localities)):\n",
    "    if type(localities[i]) == float:\n",
    "        localities[i] = 'NOT AVAILABLE'\n",
    "    localities[i] = localities[i].strip().upper()   \n",
    "    \n",
    "\n",
    "#Cleaning Rating\n",
    "\n",
    "rating = list(df_test['RATING'])\n",
    "\n",
    "for i in range(len(rating)) :\n",
    "    try:\n",
    "       rating[i] = float(rating[i])\n",
    "    except :\n",
    "       rating[i] = np.nan\n",
    "\n",
    "\n",
    "# Votes\n",
    "       \n",
    "votes = list(df_test['VOTES'])\n",
    "\n",
    "for i in range(len(votes)) :\n",
    "    try:\n",
    "       votes[i] = int(votes[i].split(\" \")[0].strip())\n",
    "    except :\n",
    "       pass    \n",
    "    \n",
    "\n",
    "    \n",
    "test_df = {}\n",
    "\n",
    "test_df['TITLE1'] = T1\n",
    "test_df['TITLE2'] = T2\n",
    "test_df['RESTAURANT_ID'] = df_test[\"RESTAURANT_ID\"]\n",
    "test_df['CUISINE1'] = C1\n",
    "test_df['CUISINE2'] = C2\n",
    "test_df['CUISINE3'] = C3\n",
    "test_df['CUISINE4'] = C4\n",
    "test_df['CUISINE5'] = C5\n",
    "test_df['CUISINE6'] = C6\n",
    "test_df['CUISINE7'] = C7\n",
    "test_df['CUISINE8'] = C8\n",
    "test_df['CITY'] = cities\n",
    "test_df['LOCALITY'] = localities\n",
    "test_df['RATING'] = rating\n",
    "test_df['VOTES'] = votes \n",
    "\n",
    "\n",
    "test_df = pd.DataFrame(test_df) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE1</th>\n",
       "      <th>TITLE2</th>\n",
       "      <th>RESTAURANT_ID</th>\n",
       "      <th>CUISINE1</th>\n",
       "      <th>CUISINE2</th>\n",
       "      <th>CUISINE3</th>\n",
       "      <th>CUISINE4</th>\n",
       "      <th>CUISINE5</th>\n",
       "      <th>CUISINE6</th>\n",
       "      <th>CUISINE7</th>\n",
       "      <th>CUISINE8</th>\n",
       "      <th>CITY</th>\n",
       "      <th>LOCALITY</th>\n",
       "      <th>RATING</th>\n",
       "      <th>VOTES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CASUAL DINING</td>\n",
       "      <td>NONE</td>\n",
       "      <td>4085</td>\n",
       "      <td>NORTH INDIAN</td>\n",
       "      <td>CHINESE</td>\n",
       "      <td>MUGHLAI</td>\n",
       "      <td>KEBAB</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NOIDA</td>\n",
       "      <td>SECTOR 18</td>\n",
       "      <td>4.3</td>\n",
       "      <td>564.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QUICK BITES</td>\n",
       "      <td>NONE</td>\n",
       "      <td>12680</td>\n",
       "      <td>SOUTH INDIAN</td>\n",
       "      <td>FAST FOOD</td>\n",
       "      <td>PIZZA</td>\n",
       "      <td>NORTH INDIAN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>GRANT ROAD</td>\n",
       "      <td>4.2</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CASUAL DINING</td>\n",
       "      <td>NONE</td>\n",
       "      <td>1411</td>\n",
       "      <td>NORTH INDIAN</td>\n",
       "      <td>SEAFOOD</td>\n",
       "      <td>BIRYANI</td>\n",
       "      <td>CHINESE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>MARINE LINES</td>\n",
       "      <td>3.8</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>204</td>\n",
       "      <td>BIRYANI</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>FARIDABAD</td>\n",
       "      <td>NIT</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1445.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QUICK BITES</td>\n",
       "      <td>NONE</td>\n",
       "      <td>13453</td>\n",
       "      <td>SOUTH INDIAN</td>\n",
       "      <td>KERALA</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>KOCHI</td>\n",
       "      <td>KALOOR</td>\n",
       "      <td>3.6</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TITLE1 TITLE2  RESTAURANT_ID      CUISINE1   CUISINE2 CUISINE3  \\\n",
       "0  CASUAL DINING   NONE           4085  NORTH INDIAN    CHINESE  MUGHLAI   \n",
       "1    QUICK BITES   NONE          12680  SOUTH INDIAN  FAST FOOD    PIZZA   \n",
       "2  CASUAL DINING   NONE           1411  NORTH INDIAN    SEAFOOD  BIRYANI   \n",
       "3           NONE   NONE            204       BIRYANI       NONE     NONE   \n",
       "4    QUICK BITES   NONE          13453  SOUTH INDIAN     KERALA     NONE   \n",
       "\n",
       "       CUISINE4 CUISINE5 CUISINE6 CUISINE7 CUISINE8       CITY      LOCALITY  \\\n",
       "0         KEBAB     NONE     NONE     NONE     NONE      NOIDA     SECTOR 18   \n",
       "1  NORTH INDIAN     NONE     NONE     NONE     NONE     MUMBAI    GRANT ROAD   \n",
       "2       CHINESE     NONE     NONE     NONE     NONE     MUMBAI  MARINE LINES   \n",
       "3          NONE     NONE     NONE     NONE     NONE  FARIDABAD           NIT   \n",
       "4          NONE     NONE     NONE     NONE     NONE      KOCHI        KALOOR   \n",
       "\n",
       "   RATING   VOTES  \n",
       "0     4.3   564.0  \n",
       "1     4.2    61.0  \n",
       "2     3.8   350.0  \n",
       "3     3.8  1445.0  \n",
       "4     3.6    23.0  "
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TITLE1              0\n",
       "TITLE2              0\n",
       "RESTAURANT_ID       0\n",
       "CUISINE1            0\n",
       "CUISINE2            0\n",
       "CUISINE3            0\n",
       "CUISINE4            0\n",
       "CUISINE5            0\n",
       "CUISINE6            0\n",
       "CUISINE7            0\n",
       "CUISINE8            0\n",
       "CITY                0\n",
       "LOCALITY            0\n",
       "RATING           1204\n",
       "VOTES            1204\n",
       "COST                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's see how many missing values are we left with\n",
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TITLE1             0\n",
       "TITLE2             0\n",
       "RESTAURANT_ID      0\n",
       "CUISINE1           0\n",
       "CUISINE2           0\n",
       "CUISINE3           0\n",
       "CUISINE4           0\n",
       "CUISINE5           0\n",
       "CUISINE6           0\n",
       "CUISINE7           0\n",
       "CUISINE8           0\n",
       "CITY               0\n",
       "LOCALITY           0\n",
       "RATING           402\n",
       "VOTES            402\n",
       "dtype: int64"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let us replace these values with 0\n",
    "test_df.fillna(0, inplace = True)\n",
    "train_df.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "#now,we have all the data in titles, cuisine, city and locality in categorical format. W need to use Label Encoding here\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_titles = LabelEncoder()\n",
    "le_cuisines = LabelEncoder()\n",
    "le_city = LabelEncoder()\n",
    "le_locality = LabelEncoder()\n",
    "le_titles.fit(all_titles)\n",
    "le_cuisines.fit(all_cuisines)\n",
    "le_city.fit(all_cities)\n",
    "le_locality.fit(all_localities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying the encoding on training and testing sets\n",
    "train_df['TITLE1'] = le_titles.transform(train_df['TITLE1'])\n",
    "train_df['TITLE2'] = le_titles.transform(train_df['TITLE2'])\n",
    "train_df['CUISINE1'] = le_cuisines.transform(train_df['CUISINE1'])\n",
    "train_df['CUISINE2'] = le_cuisines.transform(train_df['CUISINE2'])\n",
    "train_df['CUISINE3'] = le_cuisines.transform(train_df['CUISINE3'])\n",
    "train_df['CUISINE4'] = le_cuisines.transform(train_df['CUISINE4'])\n",
    "train_df['CUISINE5'] = le_cuisines.transform(train_df['CUISINE5'])\n",
    "train_df['CUISINE6'] = le_cuisines.transform(train_df['CUISINE6'])\n",
    "train_df['CUISINE7'] = le_cuisines.transform(train_df['CUISINE7'])\n",
    "train_df['CUISINE8'] = le_cuisines.transform(train_df['CUISINE8'])\n",
    "train_df['CITY'] = le_city.transform(train_df['CITY'])\n",
    "train_df['LOCALITY'] = le_locality.transform(train_df['LOCALITY']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['TITLE1'] = le_titles.transform(test_df['TITLE1'])\n",
    "test_df['TITLE2'] = le_titles.transform(test_df['TITLE2'])\n",
    "test_df['CUISINE1'] = le_cuisines.transform(test_df['CUISINE1'])\n",
    "test_df['CUISINE2'] = le_cuisines.transform(test_df['CUISINE2'])\n",
    "test_df['CUISINE3'] = le_cuisines.transform(test_df['CUISINE3'])\n",
    "test_df['CUISINE4'] = le_cuisines.transform(test_df['CUISINE4'])\n",
    "test_df['CUISINE5'] = le_cuisines.transform(test_df['CUISINE5'])\n",
    "test_df['CUISINE6'] = le_cuisines.transform(test_df['CUISINE6'])\n",
    "test_df['CUISINE7'] = le_cuisines.transform(test_df['CUISINE7'])\n",
    "test_df['CUISINE8'] = le_cuisines.transform(test_df['CUISINE8'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE1</th>\n",
       "      <th>TITLE2</th>\n",
       "      <th>RESTAURANT_ID</th>\n",
       "      <th>CUISINE1</th>\n",
       "      <th>CUISINE2</th>\n",
       "      <th>CUISINE3</th>\n",
       "      <th>CUISINE4</th>\n",
       "      <th>CUISINE5</th>\n",
       "      <th>CUISINE6</th>\n",
       "      <th>CUISINE7</th>\n",
       "      <th>CUISINE8</th>\n",
       "      <th>CITY</th>\n",
       "      <th>LOCALITY</th>\n",
       "      <th>RATING</th>\n",
       "      <th>VOTES</th>\n",
       "      <th>COST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>9438</td>\n",
       "      <td>74</td>\n",
       "      <td>47</td>\n",
       "      <td>92</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>408</td>\n",
       "      <td>320</td>\n",
       "      <td>3.6</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>13198</td>\n",
       "      <td>7</td>\n",
       "      <td>82</td>\n",
       "      <td>62</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>75</td>\n",
       "      <td>1204</td>\n",
       "      <td>4.2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10915</td>\n",
       "      <td>92</td>\n",
       "      <td>29</td>\n",
       "      <td>17</td>\n",
       "      <td>55</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>75</td>\n",
       "      <td>1261</td>\n",
       "      <td>3.8</td>\n",
       "      <td>221.0</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>6346</td>\n",
       "      <td>126</td>\n",
       "      <td>29</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>280</td>\n",
       "      <td>149</td>\n",
       "      <td>4.1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>15387</td>\n",
       "      <td>34</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>280</td>\n",
       "      <td>700</td>\n",
       "      <td>3.8</td>\n",
       "      <td>165.0</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TITLE1  TITLE2  RESTAURANT_ID  CUISINE1  CUISINE2  CUISINE3  CUISINE4  \\\n",
       "0       5      20           9438        74        47        92        90   \n",
       "1       5       1          13198         7        82        62        90   \n",
       "2       5      20          10915        92        29        17        55   \n",
       "3      23      20           6346       126        29        90        90   \n",
       "4       9      20          15387        34        90        90        90   \n",
       "\n",
       "   CUISINE5  CUISINE6  CUISINE7  CUISINE8  CITY  LOCALITY  RATING  VOTES  COST  \n",
       "0        90        90        90        90   408       320     3.6   49.0  1200  \n",
       "1        90        90        90        90    75      1204     4.2   30.0  1500  \n",
       "2        90        90        90        90    75      1261     3.8  221.0   800  \n",
       "3        90        90        90        90   280       149     4.1   24.0   800  \n",
       "4        90        90        90        90   280       700     3.8  165.0   300  "
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE1</th>\n",
       "      <th>TITLE2</th>\n",
       "      <th>RESTAURANT_ID</th>\n",
       "      <th>CUISINE1</th>\n",
       "      <th>CUISINE2</th>\n",
       "      <th>CUISINE3</th>\n",
       "      <th>CUISINE4</th>\n",
       "      <th>CUISINE5</th>\n",
       "      <th>CUISINE6</th>\n",
       "      <th>CUISINE7</th>\n",
       "      <th>CUISINE8</th>\n",
       "      <th>CITY</th>\n",
       "      <th>LOCALITY</th>\n",
       "      <th>RATING</th>\n",
       "      <th>VOTES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>4085</td>\n",
       "      <td>92</td>\n",
       "      <td>29</td>\n",
       "      <td>86</td>\n",
       "      <td>66</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>NOIDA</td>\n",
       "      <td>SECTOR 18</td>\n",
       "      <td>4.3</td>\n",
       "      <td>564.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>12680</td>\n",
       "      <td>116</td>\n",
       "      <td>41</td>\n",
       "      <td>101</td>\n",
       "      <td>92</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>GRANT ROAD</td>\n",
       "      <td>4.2</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>1411</td>\n",
       "      <td>92</td>\n",
       "      <td>112</td>\n",
       "      <td>17</td>\n",
       "      <td>29</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>MARINE LINES</td>\n",
       "      <td>3.8</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>204</td>\n",
       "      <td>17</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>FARIDABAD</td>\n",
       "      <td>NIT</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1445.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>13453</td>\n",
       "      <td>116</td>\n",
       "      <td>67</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>KOCHI</td>\n",
       "      <td>KALOOR</td>\n",
       "      <td>3.6</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TITLE1  TITLE2  RESTAURANT_ID  CUISINE1  CUISINE2  CUISINE3  CUISINE4  \\\n",
       "0       5      20           4085        92        29        86        66   \n",
       "1      23      20          12680       116        41       101        92   \n",
       "2       5      20           1411        92       112        17        29   \n",
       "3      20      20            204        17        90        90        90   \n",
       "4      23      20          13453       116        67        90        90   \n",
       "\n",
       "   CUISINE5  CUISINE6  CUISINE7  CUISINE8       CITY      LOCALITY  RATING  \\\n",
       "0        90        90        90        90      NOIDA     SECTOR 18     4.3   \n",
       "1        90        90        90        90     MUMBAI    GRANT ROAD     4.2   \n",
       "2        90        90        90        90     MUMBAI  MARINE LINES     3.8   \n",
       "3        90        90        90        90  FARIDABAD           NIT     3.8   \n",
       "4        90        90        90        90      KOCHI        KALOOR     3.6   \n",
       "\n",
       "    VOTES  \n",
       "0   564.0  \n",
       "1    61.0  \n",
       "2   350.0  \n",
       "3  1445.0  \n",
       "4    23.0  "
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping Restaurant id as it is useless for our modelling\n",
    "train_df.drop(columns=['RESTAURANT_ID'], axis=1,inplace=True)\n",
    "test_df.drop(columns=['RESTAURANT_ID'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting dataset into independent and dependent variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=train_df.drop(columns=['COST'],axis=1)\n",
    "y=train_df['COST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test= train_test_split(x,y,random_state=42,test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10152, 14) \t (2538, 14)\n"
     ]
    }
   ],
   "source": [
    "#Checking the shape\n",
    "print(x_train.shape,'\\t',x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing our models Library\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "#Importing Errors Metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "#Importing Boosting models\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_score of LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False) is 0.19570665905598983\n",
      "Error_train:\n",
      "Mean absolute error_train:  317.71669393135517\n",
      "Mean squared error_train:  322789.2418364376\n",
      "Root mean squared error_train:  568.1454407424543\n",
      "r2 score_train:  0.19570665905598983\n",
      "***********************************************************************\n",
      "\n",
      "\n",
      "test_score of LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False) is 0.20841229182584076\n",
      "Error_test:\n",
      "Mean absolute error_test:  306.9734112458632\n",
      "Mean squared error_test:  284892.3151408645\n",
      "Root mean squared error_test:  533.7530469616679\n",
      "r2 score_test:  0.20841229182584076\n",
      "***********************************************************************\n",
      "\n",
      "\n",
      "train_score of DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=None, splitter='best') is 0.999813503073076\n",
      "Error_train:\n",
      "Mean absolute error_train:  0.6121946414499606\n",
      "Mean squared error_train:  74.84732072498029\n",
      "Root mean squared error_train:  8.65143460502247\n",
      "r2 score_train:  0.999813503073076\n",
      "***********************************************************************\n",
      "\n",
      "\n",
      "test_score of DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=None, splitter='best') is 0.3606095220216933\n",
      "Error_test:\n",
      "Mean absolute error_test:  250.5744680851064\n",
      "Mean squared error_test:  230116.55141843972\n",
      "Root mean squared error_test:  479.70465019472107\n",
      "r2 score_test:  0.3606095220216933\n",
      "***********************************************************************\n",
      "\n",
      "\n",
      "train_score of KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                    weights='uniform') is 0.38446737949153575\n",
      "Error_train:\n",
      "Mean absolute error_train:  294.3599290780142\n",
      "Mean squared error_train:  247033.3866824271\n",
      "Root mean squared error_train:  497.02453328022665\n",
      "r2 score_train:  0.38446737949153575\n",
      "***********************************************************************\n",
      "\n",
      "\n",
      "test_score of KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                    weights='uniform') is 0.03925518640554759\n",
      "Error_test:\n",
      "Mean absolute error_test:  342.7276595744681\n",
      "Mean squared error_test:  345771.93579196214\n",
      "Root mean squared error_test:  588.0237544453133\n",
      "r2 score_test:  0.03925518640554759\n",
      "***********************************************************************\n",
      "\n",
      "\n",
      "train_score of SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False) is 0.034096409092394864\n",
      "Error_train:\n",
      "Mean absolute error_train:  326.62890772916234\n",
      "Mean squared error_train:  387648.72456884215\n",
      "Root mean squared error_train:  622.6144268878148\n",
      "r2 score_train:  0.034096409092394864\n",
      "***********************************************************************\n",
      "\n",
      "\n",
      "test_score of SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False) is 0.04323082003472167\n",
      "Error_test:\n",
      "Mean absolute error_test:  315.3162317423504\n",
      "Mean squared error_test:  344341.10575623595\n",
      "Root mean squared error_test:  586.8058501380469\n",
      "r2 score_test:  0.04323082003472167\n",
      "***********************************************************************\n",
      "\n",
      "\n",
      "train_score of Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=None,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False) is 0.1957045165504162\n",
      "Error_train:\n",
      "Mean absolute error_train:  317.567262090082\n",
      "Mean squared error_train:  322790.10169404745\n",
      "Root mean squared error_train:  568.1461974650956\n",
      "r2 score_train:  0.1957045165504162\n",
      "***********************************************************************\n",
      "\n",
      "\n",
      "test_score of Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=None,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False) is 0.2084244044442306\n",
      "Error_test:\n",
      "Mean absolute error_test:  306.8209866748112\n",
      "Mean squared error_test:  284887.95581105194\n",
      "Root mean squared error_test:  533.7489632880348\n",
      "r2 score_test:  0.2084244044442306\n",
      "***********************************************************************\n",
      "\n",
      "\n",
      "train_score of Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=False, random_state=None, solver='auto', tol=0.001) is 0.19570665894163042\n",
      "Error_train:\n",
      "Mean absolute error_train:  317.7155202009341\n",
      "Mean squared error_train:  322789.2418823338\n",
      "Root mean squared error_train:  568.1454407828455\n",
      "r2 score_train:  0.19570665894163042\n",
      "***********************************************************************\n",
      "\n",
      "\n",
      "test_score of Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=False, random_state=None, solver='auto', tol=0.001) is 0.2084124116418824\n",
      "Error_test:\n",
      "Mean absolute error_test:  306.9721520694337\n",
      "Mean squared error_test:  284892.27201908646\n",
      "Root mean squared error_test:  533.7530065667888\n",
      "r2 score_test:  0.2084124116418824\n",
      "***********************************************************************\n",
      "\n",
      "\n",
      "train_score of ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
      "           max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "           random_state=None, selection='cyclic', tol=0.0001, warm_start=False) is 0.19413581828669657\n",
      "Error_train:\n",
      "Mean absolute error_train:  314.34441665872566\n",
      "Mean squared error_train:  323419.6716499815\n",
      "Root mean squared error_train:  568.699983866697\n",
      "r2 score_train:  0.19413581828669657\n",
      "***********************************************************************\n",
      "\n",
      "\n",
      "test_score of ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
      "           max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "           random_state=None, selection='cyclic', tol=0.0001, warm_start=False) is 0.2071638766092344\n",
      "Error_test:\n",
      "Mean absolute error_test:  303.3783357566818\n",
      "Mean squared error_test:  285341.61961798486\n",
      "Root mean squared error_test:  534.1737728660822\n",
      "r2 score_test:  0.2071638766092344\n",
      "***********************************************************************\n",
      "\n",
      "\n",
      "train_score of RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=None, verbose=0, warm_start=False) is 0.9526548187482543\n",
      "Error_train:\n",
      "Mean absolute error_train:  72.4999936953424\n",
      "Mean squared error_train:  19001.17082024132\n",
      "Root mean squared error_train:  137.84473446686792\n",
      "r2 score_train:  0.9526548187482543\n",
      "***********************************************************************\n",
      "\n",
      "\n",
      "test_score of RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=None, verbose=0, warm_start=False) is 0.7347447055427676\n",
      "Error_test:\n",
      "Mean absolute error_test:  184.74322900197603\n",
      "Mean squared error_test:  95465.3466203981\n",
      "Root mean squared error_test:  308.9746698685802\n",
      "r2 score_test:  0.7347447055427676\n",
      "***********************************************************************\n",
      "\n",
      "\n",
      "train_score of AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=None) is -0.3591791912984532\n",
      "Error_train:\n",
      "Mean absolute error_train:  607.876615015566\n",
      "Mean squared error_train:  545483.0947178408\n",
      "Root mean squared error_train:  738.568273565715\n",
      "r2 score_train:  -0.3591791912984532\n",
      "***********************************************************************\n",
      "\n",
      "\n",
      "test_score of AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=None) is -0.5400508056463509\n",
      "Error_test:\n",
      "Mean absolute error_test:  613.9460325515133\n",
      "Mean squared error_test:  554264.0883941218\n",
      "Root mean squared error_test:  744.4891459209609\n",
      "r2 score_test:  -0.5400508056463509\n",
      "***********************************************************************\n",
      "\n",
      "\n",
      "train_score of GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=None, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False) is 0.7144579659069149\n",
      "Error_train:\n",
      "Mean absolute error_train:  193.95805645465086\n",
      "Mean squared error_train:  114597.3639283897\n",
      "Root mean squared error_train:  338.52232412115706\n",
      "r2 score_train:  0.7144579659069149\n",
      "***********************************************************************\n",
      "\n",
      "\n",
      "test_score of GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=None, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False) is 0.715227920789367\n",
      "Error_test:\n",
      "Mean absolute error_test:  194.07239530753262\n",
      "Mean squared error_test:  102489.43496220306\n",
      "Root mean squared error_test:  320.13971162947445\n",
      "r2 score_test:  0.715227920789367\n",
      "***********************************************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using algorithms via for loop\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#RMSE Scores (Train & Test)\n",
    "model=[LinearRegression(),DecisionTreeRegressor(),KNeighborsRegressor(),SVR(), Lasso(), Ridge(), ElasticNet(), RandomForestRegressor(), AdaBoostRegressor(), GradientBoostingRegressor()]\n",
    "for m in model:\n",
    "    m.fit(x_train,y_train)\n",
    "    print('train_score of',m,'is',m.score(x_train,y_train))\n",
    "    pred_train=m.predict(x_train)\n",
    "    pred_test=m.predict(x_test)\n",
    "    print('Error_train:')\n",
    "    print('Mean absolute error_train: ',mean_absolute_error(y_train,pred_train))\n",
    "    print('Mean squared error_train: ',mean_squared_error(y_train,pred_train))\n",
    "    print('Root mean squared error_train: ',np.sqrt(mean_squared_error(y_train,pred_train)))\n",
    "    print('r2 score_train: ',r2_score(y_train,pred_train))\n",
    "    print('***********************************************************************')\n",
    "    print('\\n')\n",
    "    print('test_score of',m,'is',m.score(x_test,y_test))\n",
    "    print('Error_test:')\n",
    "    print('Mean absolute error_test: ',mean_absolute_error(y_test,pred_test))\n",
    "    print('Mean squared error_test: ',mean_squared_error(y_test,pred_test))\n",
    "    print('Root mean squared error_test: ',np.sqrt(mean_squared_error(y_test,pred_test)))\n",
    "    print('r2 score_test: ',r2_score(y_test,pred_test))\n",
    "    print('***********************************************************************')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data_score of LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False) is: \n",
      "Score:  [0.25820359 0.20106911 0.19297981 0.15873003 0.1291967  0.18626496\n",
      " 0.21584346]\n",
      "Mean Score: 0.19175538042123946\n",
      "Standard Deviation 0.038019266332685\n",
      "**********************************************************\n",
      "test_data_score of LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False) is: \n",
      "Score:  [0.21813804 0.1176986  0.2579185  0.22037297 0.23868735 0.23900126\n",
      " 0.15323166]\n",
      "Mean Score: 0.20643548215682128\n",
      "Standard Deviation 0.04749029967798254\n",
      "**********************************************************\n",
      "\n",
      "\n",
      "train_data_score of DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=None, splitter='best') is: \n",
      "Score:  [0.3835152  0.25737    0.4988295  0.37836432 0.52107952 0.45218115\n",
      " 0.53999873]\n",
      "Mean Score: 0.4330483450422085\n",
      "Standard Deviation 0.09272682895732756\n",
      "**********************************************************\n",
      "test_data_score of DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=None, splitter='best') is: \n",
      "Score:  [0.45793495 0.38867388 0.44342233 0.44563368 0.56298797 0.4287179\n",
      " 0.35094015]\n",
      "Mean Score: 0.43975869443044996\n",
      "Standard Deviation 0.06116027823637074\n",
      "**********************************************************\n",
      "\n",
      "\n",
      "train_data_score of KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                    weights='uniform') is: \n",
      "Score:  [0.02176171 0.0452211  0.06168489 0.08132778 0.11013487 0.0595573\n",
      " 0.01357416]\n",
      "Mean Score: 0.056180259566064095\n",
      "Standard Deviation 0.030949781916164754\n",
      "**********************************************************\n",
      "test_data_score of KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                    weights='uniform') is: \n",
      "Score:  [-0.01437527  0.0006954  -0.1282387   0.04043779  0.03407743 -0.02957031\n",
      " -0.047549  ]\n",
      "Mean Score: -0.020646092360853446\n",
      "Standard Deviation 0.052915383941302796\n",
      "**********************************************************\n",
      "\n",
      "\n",
      "train_data_score of SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False) is: \n",
      "Score:  [0.04954407 0.02908548 0.02958206 0.02156661 0.03712929 0.02498888\n",
      " 0.01055308]\n",
      "Mean Score: 0.028921351627133194\n",
      "Standard Deviation 0.011339438410904679\n",
      "**********************************************************\n",
      "test_data_score of SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False) is: \n",
      "Score:  [-0.04832702 -0.03706136 -0.01407682 -0.05606991 -0.05090916 -0.02353698\n",
      " -0.0461214 ]\n",
      "Mean Score: -0.039443234793325246\n",
      "Standard Deviation 0.014310688860813702\n",
      "**********************************************************\n",
      "\n",
      "\n",
      "train_data_score of Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=None,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False) is: \n",
      "Score:  [0.25834589 0.20106734 0.19305886 0.15874466 0.12884269 0.18632498\n",
      " 0.21584108]\n",
      "Mean Score: 0.19174649979760733\n",
      "Standard Deviation 0.03813515772374381\n",
      "**********************************************************\n",
      "test_data_score of Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=None,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False) is: \n",
      "Score:  [0.21808667 0.11771075 0.25816776 0.2203135  0.23889663 0.23890154\n",
      " 0.15304684]\n",
      "Mean Score: 0.20644624164696154\n",
      "Standard Deviation 0.04756164980146837\n",
      "**********************************************************\n",
      "\n",
      "\n",
      "train_data_score of Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=False, random_state=None, solver='auto', tol=0.001) is: \n",
      "Score:  [0.25820446 0.20106895 0.19298005 0.15872995 0.12919427 0.18626557\n",
      " 0.21584362]\n",
      "Mean Score: 0.1917552680366832\n",
      "Standard Deviation 0.03802006379046454\n",
      "**********************************************************\n",
      "test_data_score of Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=False, random_state=None, solver='auto', tol=0.001) is: \n",
      "Score:  [0.21813542 0.11769626 0.25792685 0.22037389 0.23869454 0.23899785\n",
      " 0.15322765]\n",
      "Mean Score: 0.20643606718505053\n",
      "Standard Deviation 0.0474931670454792\n",
      "**********************************************************\n",
      "\n",
      "\n",
      "train_data_score of ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
      "           max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "           random_state=None, selection='cyclic', tol=0.0001, warm_start=False) is: \n",
      "Score:  [0.25882083 0.19927258 0.19239942 0.1573304  0.11971229 0.1865307\n",
      " 0.21449316]\n",
      "Mean Score: 0.18979419800227618\n",
      "Standard Deviation 0.04043930939256362\n",
      "**********************************************************\n",
      "test_data_score of ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
      "           max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "           random_state=None, selection='cyclic', tol=0.0001, warm_start=False) is: \n",
      "Score:  [0.21429694 0.11451696 0.26227877 0.2197315  0.24221701 0.23485312\n",
      " 0.14861411]\n",
      "Mean Score: 0.20521548524749425\n",
      "Standard Deviation 0.04960824598627623\n",
      "**********************************************************\n",
      "\n",
      "\n",
      "train_data_score of RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=None, verbose=0, warm_start=False) is: \n",
      "Score:  [0.73022788 0.68706698 0.69640377 0.61789873 0.67520459 0.67326667\n",
      " 0.75831382]\n",
      "Mean Score: 0.6911974923928152\n",
      "Standard Deviation 0.04144210038827827\n",
      "**********************************************************\n",
      "test_data_score of RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=None, verbose=0, warm_start=False) is: \n",
      "Score:  [0.69219461 0.7435985  0.65839832 0.65003253 0.71039316 0.69072279\n",
      " 0.72622171]\n",
      "Mean Score: 0.695937372070255\n",
      "Standard Deviation 0.03152171592339044\n",
      "**********************************************************\n",
      "\n",
      "\n",
      "train_data_score of AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=None) is: \n",
      "Score:  [-1.08396306 -0.27718725 -0.17505302 -0.59564515 -0.34835971 -0.79371175\n",
      " -0.41873388]\n",
      "Mean Score: -0.5275219740960974\n",
      "Standard Deviation 0.2966383674403527\n",
      "**********************************************************\n",
      "test_data_score of AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "                  n_estimators=50, random_state=None) is: \n",
      "Score:  [ 0.13410791  0.0159073  -0.31771906 -0.41028537 -0.55068423  0.49123654\n",
      "  0.34675971]\n",
      "Mean Score: -0.041525314084198794\n",
      "Standard Deviation 0.366500002420224\n",
      "**********************************************************\n",
      "\n",
      "\n",
      "train_data_score of GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=None, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False) is: \n",
      "Score:  [0.74514738 0.70637145 0.6867679  0.57535318 0.67214761 0.70092847\n",
      " 0.7391288 ]\n",
      "Mean Score: 0.6894063971917995\n",
      "Standard Deviation 0.05252606261592726\n",
      "**********************************************************\n",
      "test_data_score of GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=None, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False) is: \n",
      "Score:  [0.71583739 0.72902834 0.64272271 0.59016879 0.62985132 0.64720975\n",
      " 0.74776929]\n",
      "Mean Score: 0.6717982260501651\n",
      "Standard Deviation 0.054588358363788426\n",
      "**********************************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Cross validate the models Code_r2 as scoring parameter:\n",
    "from sklearn.model_selection import cross_val_score\n",
    "model=[LinearRegression(),DecisionTreeRegressor(),KNeighborsRegressor(),SVR(), Lasso(), Ridge(), ElasticNet(), RandomForestRegressor(), AdaBoostRegressor(), GradientBoostingRegressor()]\n",
    "for m in model:\n",
    "    train_data_score=cross_val_score(m,x_train,y_train,cv=7,scoring='r2')\n",
    "    test_data_score=cross_val_score(m,x_test,y_test,cv=7,scoring='r2')\n",
    "    print('train_data_score of',m,'is: ')\n",
    "    print('Score: ',train_data_score)\n",
    "    print('Mean Score:',train_data_score.mean())\n",
    "    print('Standard Deviation',train_data_score.std())\n",
    "    print('**********************************************************')\n",
    "    print('test_data_score of',m,'is: ')\n",
    "    print('Score: ',test_data_score)\n",
    "    print('Mean Score:',test_data_score.mean())\n",
    "    print('Standard Deviation',test_data_score.std())\n",
    "    print('**********************************************************')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We have achieved an accuracy of almost 69% using Random Forest Regressor. Hence, we will move forward with that model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-294-49cfb51e6469>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mRFC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRFC\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\mayan\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    708\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 710\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\mayan\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1482\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[0;32m   1483\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1484\u001b[1;33m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[1;32md:\\Users\\mayan\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    687\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 689\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\mayan\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\mayan\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    833\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\mayan\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\mayan\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\mayan\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\mayan\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\mayan\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\mayan\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 515\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    516\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\mayan\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    381\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[1;32m--> 383\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\mayan\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\mayan\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    833\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\mayan\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\mayan\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\mayan\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\mayan\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\mayan\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\mayan\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    163\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\mayan\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1223\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1224\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1225\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m   1226\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Users\\mayan\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    365\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 367\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Using GridsearchCV to find the best parameters\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "parameters={'n_estimators':[400,500,600,700], 'max_depth':[4,5,6,15,20]}\n",
    "RFC=RandomForestRegressor()\n",
    "clf=RandomizedSearchCV(RFC,parameters)\n",
    "clf.fit(x,y)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using Random Forest Regressor with its best parameters\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf=RandomForestRegressor(n_estimators=)\n",
    "rf.fit(x_train,y_train)\n",
    "print('Score',rf.score(x_train,y_train))\n",
    "y_pred=rf.predict(x_test)\n",
    "print('\\n')\n",
    "print('Mean absolute error:', mean_absolute_error(y_test,y_pred))\n",
    "print('Mean squared error:', mean_squared_error(y_test,y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test,y_pred)))\n",
    "print('\\n')\n",
    "print(\"r2_score:\"r2_score(y_test,y_pred))\n",
    "print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
